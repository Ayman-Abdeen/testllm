{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayman-Abdeen/testllm/blob/main/ollama_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RWwo_hQ0Xqz",
        "outputId": "3b69040e-ed8c-4331-96cd-a920fa7c98a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WB8dN1S0ak2",
        "outputId": "97ca7a28-7847-4dad-8410-8fc600882026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#curl -fsSL https://ollama.com/install.sh | sh\n",
        "#ollama serve & ollama run llama3\n",
        "#ollama pull nomic-embed-text"
      ],
      "metadata": {
        "id": "C_FxqOAW08rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-community langchain-text-splitters chromadb"
      ],
      "metadata": {
        "id": "NguJwmtD2xqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader ,TextLoader"
      ],
      "metadata": {
        "id": "KvGs6H8_2N0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = \"/content/Data.txt\"\n",
        "\n",
        "# Local PDF file uploads\n",
        "if local_path:\n",
        "  loader = TextLoader(file_path=local_path)\n",
        "  data = loader.load()\n",
        "else:\n",
        "  print(\"Upload a PDF file\")"
      ],
      "metadata": {
        "id": "4f_hh2rl2qyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo6Ub0m24LHn",
        "outputId": "725d2bd4-582f-4f70-895f-b7f17ac883ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!"
      ],
      "metadata": {
        "id": "e830mhDQ4myJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2WD6kvl4NmS",
        "outputId": "bb00302a-9ee9-413f-da99-29988dc2dc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                   \tID          \tSIZE  \tMODIFIED       \n",
            "nomic-embed-text:latest\t0a109f422b47\t274 MB\t18 seconds ago\t\n",
            "llama3:latest          \t365c0bd3c000\t4.7 GB\t18 minutes ago\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "ijfMUOUn4iHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split and chunk\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=30,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False\n",
        "    )\n",
        "chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "EJPTNfeb9Bv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "id": "QzTvq00093vM",
        "outputId": "e9925ac0-934e-4b4c-8548-f0999bf13f79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "470"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks[0].page_content)"
      ],
      "metadata": {
        "id": "Vn2ZLlao-w8b",
        "outputId": "f647a725-b44c-4dac-f663-3982de1a3853",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UAE achieves 30% of Operation 300bn’s target since its 2021 launch, with the\n",
            "industrial sector’s contribution to GDP reaching a projected AED 197 billion.\n",
            "UAE industrial exports increase by 17% since the launch of Operation 300bn in\n",
            "2021, reaching projected AED 187 billion in 2023.\n",
            "AED 9.3bn value of import substitution projects.\n",
            "The value spent by National In County Value (ICV) companies in 2023 on local products\n",
            "and services increased by 25% to reach AED 67 billion, redirected to the national\n",
            "economy.\n",
            "Introduce 1,400 products that can be manufactured locally through the offtake project\n",
            "during the 1st and 2nd editions of MIITE, with a total value of AED 120 billion. Of these,\n",
            "51 percent of the product offtake opportunities, equivalent to AED 62 billion, have been\n",
            "awarded.\n",
            "During the 3rd edition of MIITE, introduce new offtake products worth AED 20 billion,\n",
            "bringing the total value of products targeted for localization to AED 140 billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add to vector database\n",
        "vector_db = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),\n",
        "    collection_name=\"local-rag\",\n",
        "    persist_directory=\"./chroma_db\",\n",
        ")"
      ],
      "metadata": {
        "id": "Z7Q8Ai9a_iBe",
        "outputId": "f5252a95-50b4-4bea-a96e-2277e90093ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OllamaEmbeddings: 100%|██████████| 470/470 [12:43<00:00,  1.62s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load from disk\n",
        "vector_db1 = Chroma(\n",
        "    persist_directory=\"./chroma_db\",\n",
        "    #embedding_function=embedding_function\n",
        "    embedding_function=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),\n",
        "    collection_name=\"local-rag\",\n",
        "    )"
      ],
      "metadata": {
        "id": "pY1Aqi-qKxMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieval"
      ],
      "metadata": {
        "id": "YBbBhiMGDUU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever"
      ],
      "metadata": {
        "id": "jNDBMu0jAP9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM from Ollama\n",
        "local_model = \"llama3\"\n",
        "llm = ChatOllama(model=local_model)"
      ],
      "metadata": {
        "id": "UXqvVL8fDTPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "    different versions of the given user question to retrieve relevant documents from\n",
        "    a vector database. By generating multiple perspectives on the user question, your\n",
        "    goal is to help the user overcome some of the limitations of the distance-based\n",
        "    similarity search. Provide these alternative questions separated by newlines.\n",
        "    Original question: {question}\"\"\",\n",
        ")"
      ],
      "metadata": {
        "id": "0WIMneFVN1uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = MultiQueryRetriever.from_llm(\n",
        "    vector_db.as_retriever(),\n",
        "    llm,\n",
        "    prompt=QUERY_PROMPT\n",
        ")\n",
        "\n",
        "# RAG prompt\n",
        "template = \"\"\"Answer the question based ONLY on the following context:\n",
        "{context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "0fADmbnyOROq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "18uIbO0eOcQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(input(\"\"))"
      ],
      "metadata": {
        "id": "1-i3Za_qOfsr",
        "outputId": "d85a0500-0a28-408a-8b05-14dbc492e8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided context, it appears to be related to business, economy, and government initiatives in the United Arab Emirates (UAE). The documents mention various topics such as:\\n\\n* Artificial Intelligence (AI) development\\n* Economic growth and competitiveness\\n* Industrial sector expansion\\n* Innovation and technology adoption\\n* Climate change and sustainability\\n* Entrepreneurship and investment opportunities\\n\\nIt seems to be a collection of reports, speeches, and statistics related to the UAE's economic and industrial development.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke('Hi, who are you ?')"
      ],
      "metadata": {
        "id": "ZZmTRCw0Okks",
        "outputId": "d451462d-217b-4214-e48a-3c4705f02987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 12.46it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ChflmfeUvaZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}